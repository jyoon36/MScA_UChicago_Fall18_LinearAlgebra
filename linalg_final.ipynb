{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import scipy.misc\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "def convert_to_lfw(image_file_name, width=47, height=62):\n",
    "    \"\"\"\n",
    "    Convert a given PIL-compatible file to an LFW grayscale\n",
    "    image with the requested width and height.\n",
    "    \"\"\"\n",
    "    # Load, grayscale, downscale\n",
    "    image = PIL.Image.open(image_file_name)\\\n",
    "        .convert(mode=\"L\")\\\n",
    "        .resize((width, height), PIL.Image.LANCZOS)\n",
    "    \n",
    "    # Return 1D np array\n",
    "    return np.array(image).ravel(order=\"C\")\n",
    "\n",
    "\n",
    "def load_lfw_directory(path, width=47, height=62):\n",
    "    \"\"\"\n",
    "    Load all JPG files from given path into LFW\n",
    "    format np array.\n",
    "    \"\"\"\n",
    "    # Iterate through all files\n",
    "    lfw_array = np.array(())\n",
    "    lfw_labels = []\n",
    "    for file_name in os.listdir(path):\n",
    "        if file_name.lower().endswith(\"jpg\") or file_name.lower().endswith(\"jpeg\") or file_name.lower().endswith(\"png\"):\n",
    "            lfw_labels.append(file_name.split(\"_\")[0])\n",
    "            if lfw_array.shape[0] == 0:\n",
    "                lfw_array = convert_to_lfw(os.path.join(path,  file_name), width=width, height=height)\n",
    "            else:\n",
    "                lfw_array = np.vstack([lfw_array, convert_to_lfw(os.path.join(path, file_name),\n",
    "                                                                    width=width, height=height)])\n",
    "    \n",
    "    # Return\n",
    "    return lfw_array, lfw_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 3023\n",
      "n_features: 2914\n",
      "n_classes: 62\n",
      "['Alejandro Toledo' 'Alvaro Uribe' 'Amelie Mauresmo' 'Andre Agassi'\n",
      " 'Angelina Jolie' 'Ariel Sharon' 'Arnold Schwarzenegger'\n",
      " 'Atal Bihari Vajpayee' 'Bill Clinton' 'Carlos Menem' 'Colin Powell'\n",
      " 'David Beckham' 'Donald Rumsfeld' 'George Robertson' 'George W Bush'\n",
      " 'Gerhard Schroeder' 'Gloria Macapagal Arroyo' 'Gray Davis'\n",
      " 'Guillermo Coria' 'Hamid Karzai' 'Hans Blix' 'Hugo Chavez' 'Igor Ivanov'\n",
      " 'Jack Straw' 'Jacques Chirac' 'Jean Chretien' 'Jennifer Aniston'\n",
      " 'Jennifer Capriati' 'Jennifer Lopez' 'Jeremy Greenstock' 'Jiang Zemin'\n",
      " 'John Ashcroft' 'John Negroponte' 'Jose Maria Aznar' 'Juan Carlos Ferrero'\n",
      " 'Junichiro Koizumi' 'Kofi Annan' 'Laura Bush' 'Lindsay Davenport'\n",
      " 'Lleyton Hewitt' 'Luiz Inacio Lula da Silva' 'Mahmoud Abbas'\n",
      " 'Megawati Sukarnoputri' 'Michael Bloomberg' 'Naomi Watts'\n",
      " 'Nestor Kirchner' 'Paul Bremer' 'Pete Sampras' 'Recep Tayyip Erdogan'\n",
      " 'Ricardo Lagos' 'Roh Moo-hyun' 'Rudolph Giuliani' 'Saddam Hussein'\n",
      " 'Serena Williams' 'Silvio Berlusconi' 'Tiger Woods' 'Tom Daschle'\n",
      " 'Tom Ridge' 'Tony Blair' 'Vicente Fox' 'Vladimir Putin' 'Winona Ryder']\n",
      "[61 25  9 ..., 14 15 14]\n",
      "62 47\n"
     ]
    }
   ],
   "source": [
    "#fetching data from sklearn. data include people with more than 15 facial images in size reduced into 50%\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=20, resize=0.5)\n",
    "\n",
    "# n_samples, images height & width\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "#n_featrues = h * w\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# id number of targets\n",
    "y = lfw_people.target\n",
    "# target names\n",
    "target_names = lfw_people.target_names\n",
    "# the number of people\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples: %d\" % n_samples)\n",
    "print(\"n_features: %d\" % n_features)\n",
    "print(\"n_classes: %d\" % n_classes)\n",
    "print(target_names)\n",
    "print(y)\n",
    "print(h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_image_matrix, our_image_labels = load_lfw_directory('/Users/jun/Downloads/drive-download-20171202T075306Z-001/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_names = {'NATASHA':len(target_names),'JUNG':len(target_names)+1,'ELIJAH':len(target_names)+2,'ANDREW':len(target_names)+3}\n",
    "our_index = np.array([our_names[i] for i in our_image_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alejandro Toledo', 'Alvaro Uribe', 'Amelie Mauresmo',\n",
       "       'Andre Agassi', 'Angelina Jolie', 'Ariel Sharon',\n",
       "       'Arnold Schwarzenegger', 'Atal Bihari Vajpayee', 'Bill Clinton',\n",
       "       'Carlos Menem', 'Colin Powell', 'David Beckham', 'Donald Rumsfeld',\n",
       "       'George Robertson', 'George W Bush', 'Gerhard Schroeder',\n",
       "       'Gloria Macapagal Arroyo', 'Gray Davis', 'Guillermo Coria',\n",
       "       'Hamid Karzai', 'Hans Blix', 'Hugo Chavez', 'Igor Ivanov',\n",
       "       'Jack Straw', 'Jacques Chirac', 'Jean Chretien', 'Jennifer Aniston',\n",
       "       'Jennifer Capriati', 'Jennifer Lopez', 'Jeremy Greenstock',\n",
       "       'Jiang Zemin', 'John Ashcroft', 'John Negroponte',\n",
       "       'Jose Maria Aznar', 'Juan Carlos Ferrero', 'Junichiro Koizumi',\n",
       "       'Kofi Annan', 'Laura Bush', 'Lindsay Davenport', 'Lleyton Hewitt',\n",
       "       'Luiz Inacio Lula da Silva', 'Mahmoud Abbas',\n",
       "       'Megawati Sukarnoputri', 'Michael Bloomberg', 'Naomi Watts',\n",
       "       'Nestor Kirchner', 'Paul Bremer', 'Pete Sampras',\n",
       "       'Recep Tayyip Erdogan', 'Ricardo Lagos', 'Roh Moo-hyun',\n",
       "       'Rudolph Giuliani', 'Saddam Hussein', 'Serena Williams',\n",
       "       'Silvio Berlusconi', 'Tiger Woods', 'Tom Daschle', 'Tom Ridge',\n",
       "       'Tony Blair', 'Vicente Fox', 'Vladimir Putin', 'Winona Ryder',\n",
       "       'NATASHA', 'JUNG', 'ELIJAH', 'ANDREW'],\n",
       "      dtype='<U25')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name in our_names.keys():\n",
    "    target_names = np.append(target_names, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2267, 2914)\n",
      "(756, 2914)\n",
      "(2267,)\n",
      "(756,)\n"
     ]
    }
   ],
   "source": [
    "# split into a training and testing set, test_size = 25% of total, random seed = 24\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=24)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 2914)\n",
      "(21, 2914)\n",
      "(62,)\n",
      "(21,)\n"
     ]
    }
   ],
   "source": [
    "our_image_train, our_image_test, our_index_train, our_index_test = train_test_split(\n",
    "    our_image_matrix, our_index, test_size=0.25)\n",
    "\n",
    "print(our_image_train.shape)\n",
    "print(our_image_test.shape)\n",
    "print(our_index_train.shape)\n",
    "print(our_index_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329,)\n",
      "(2329, 2914)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vstack([X_train, our_image_train])\n",
    "y_train = np.append(y_train, our_index_train)\n",
    "X_test = np.vstack([X_test, our_image_test])\n",
    "y_test = np.append(y_test, our_index_test)\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 200 eigenfaces from 2329 faces\n",
      "done in 0.516s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.023s\n"
     ]
    }
   ],
   "source": [
    "#PCA components\n",
    "n_components = 200\n",
    "\n",
    "print(\"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0]))\n",
    "t0 = time()\n",
    "#using PCA module in sklearn, we are fitting trainset\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized', whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "#constructing eigenfaces using PCA fitted with trainset\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "t0 = time()\n",
    "\n",
    "#converting train and test values using PCA fitted with trainset\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(our_image_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2914)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 200)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_pca = np.matmul(our_image_test, np.transpose(pca.components_))\n",
    "manual_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ..., \n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]], dtype=bool)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca == manual_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in 276.561s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.0005, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "\n",
    "#parameter grid, cost to be 1000, 5000, 10000, 50000, 100000\n",
    "# gamma to be 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "#constructing classfication model using Support Vector Machine with kernel Radial basis function\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "\n",
    "#fitting pca train set with id of people in trainset\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "\n",
    "#best estimator with each cost and gamma parameter\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting people's names on the test set\n",
      "done in 0.019s\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "        Ariel Sharon       0.00      0.00      0.00         0\n",
      "Atal Bihari Vajpayee       0.00      0.00      0.00         0\n",
      "      Lleyton Hewitt       0.00      0.00      0.00         0\n",
      "        Winona Ryder       0.00      0.00      0.00         0\n",
      "             NATASHA       1.00      0.43      0.60         7\n",
      "                JUNG       1.00      1.00      1.00         4\n",
      "              ELIJAH       1.00      1.00      1.00         5\n",
      "              ANDREW       1.00      1.00      1.00         5\n",
      "\n",
      "         avg / total       1.00      0.81      0.87        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting people's names on the test set\")\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(classification_report(our_index_test, y_pred, target_names = target_names[[i for i in sorted(set(y_pred))]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 7, 39, 61, 62, 63, 64, 65]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [i for i in set(y_pred)]\n",
    "sorted(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 64, 62, 64,  7, 63, 63, 39, 65, 64, 65, 65, 63,  5, 61, 62, 63,\n",
       "       62, 64, 65, 65])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 64, 62, 64, 62, 63, 63, 62, 65, 64, 65, 65, 63, 62, 62, 62, 63,\n",
       "       62, 64, 65, 65])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 64, 62, 64, 14, 63, 63, 39, 65, 64, 65, 65, 63,  6, 61, 62, 63,\n",
       "       62, 64, 65, 65])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "\n",
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[int(y_pred[i])].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[int(our_index_test[i])].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prediction_titles = [title(y_pred, y_test, target_names, i) for i in range(y_pred.shape[0])]\\n\\nplot_gallery(our_image_test, prediction_titles, h, w)\\n\\n# plot the gallery of the most significative eigenfaces\\n\\neigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\\nplot_gallery(eigenfaces, eigenface_titles, h, w)\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_titles = [title(y_pred, y_test, target_names, i) for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(our_image_test, prediction_titles, h, w)\n",
    "\n",
    "# plot the gallery of the most significative eigenfaces\n",
    "\n",
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
